{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Fold: 1\n",
      "Epoch: 1, Batch: 100, Loss: 2.028508747816086\n",
      "Epoch: 1, Batch: 200, Loss: 1.6032263243198395\n",
      "Epoch: 1, Batch: 300, Loss: 1.4541489458084107\n",
      "Epoch: 1, Batch: 400, Loss: 1.3703135585784911\n",
      "Epoch: 1, Batch: 500, Loss: 1.329819307923317\n",
      "Epoch: 2, Batch: 100, Loss: 1.2252895110845565\n",
      "Epoch: 2, Batch: 200, Loss: 1.1910015231370925\n",
      "Epoch: 2, Batch: 300, Loss: 1.1673907417058944\n",
      "Epoch: 2, Batch: 400, Loss: 1.1215307450294494\n",
      "Epoch: 2, Batch: 500, Loss: 1.1059363240003586\n",
      "Epoch: 3, Batch: 100, Loss: 1.0277092742919922\n",
      "Epoch: 3, Batch: 200, Loss: 1.0414748311042785\n",
      "Epoch: 3, Batch: 300, Loss: 0.9948185276985169\n",
      "Epoch: 3, Batch: 400, Loss: 0.9935266178846359\n",
      "Epoch: 3, Batch: 500, Loss: 0.9482404285669327\n",
      "Epoch: 4, Batch: 100, Loss: 0.9204153048992157\n",
      "Epoch: 4, Batch: 200, Loss: 0.8845356512069702\n",
      "Epoch: 4, Batch: 300, Loss: 0.9000644320249558\n",
      "Epoch: 4, Batch: 400, Loss: 0.901420823931694\n",
      "Epoch: 4, Batch: 500, Loss: 0.87252481341362\n",
      "Epoch: 5, Batch: 100, Loss: 0.8139130985736847\n",
      "Epoch: 5, Batch: 200, Loss: 0.81514393389225\n",
      "Epoch: 5, Batch: 300, Loss: 0.8288780122995376\n",
      "Epoch: 5, Batch: 400, Loss: 0.8085173040628433\n",
      "Epoch: 5, Batch: 500, Loss: 0.7926709678769112\n",
      "Epoch: 6, Batch: 100, Loss: 0.7245459842681885\n",
      "Epoch: 6, Batch: 200, Loss: 0.7348738875985146\n",
      "Epoch: 6, Batch: 300, Loss: 0.738752787411213\n",
      "Epoch: 6, Batch: 400, Loss: 0.7311471509933472\n",
      "Epoch: 6, Batch: 500, Loss: 0.7455500772595406\n",
      "Epoch: 7, Batch: 100, Loss: 0.6592532229423523\n",
      "Epoch: 7, Batch: 200, Loss: 0.6654131519794464\n",
      "Epoch: 7, Batch: 300, Loss: 0.6605055192112923\n",
      "Epoch: 7, Batch: 400, Loss: 0.6912808772921563\n",
      "Epoch: 7, Batch: 500, Loss: 0.6683701008558274\n",
      "Epoch: 8, Batch: 100, Loss: 0.5934371840953827\n",
      "Epoch: 8, Batch: 200, Loss: 0.5929291582107544\n",
      "Epoch: 8, Batch: 300, Loss: 0.5901445704698562\n",
      "Epoch: 8, Batch: 400, Loss: 0.6177368709444999\n",
      "Epoch: 8, Batch: 500, Loss: 0.619443344771862\n",
      "Epoch: 9, Batch: 100, Loss: 0.5216941899061203\n",
      "Epoch: 9, Batch: 200, Loss: 0.5423831132054329\n",
      "Epoch: 9, Batch: 300, Loss: 0.5409357017278671\n",
      "Epoch: 9, Batch: 400, Loss: 0.5445065307617187\n",
      "Epoch: 9, Batch: 500, Loss: 0.5545311686396599\n",
      "Epoch: 10, Batch: 100, Loss: 0.4527661743760109\n",
      "Epoch: 10, Batch: 200, Loss: 0.4837184277176857\n",
      "Epoch: 10, Batch: 300, Loss: 0.4934067830443382\n",
      "Epoch: 10, Batch: 400, Loss: 0.4879901745915413\n",
      "Epoch: 10, Batch: 500, Loss: 0.4852776148915291\n",
      "Validation Accuracy: 69.9%\n",
      "Fold: 2\n",
      "Epoch: 1, Batch: 100, Loss: 1.983214919567108\n",
      "Epoch: 1, Batch: 200, Loss: 1.5801150846481322\n",
      "Epoch: 1, Batch: 300, Loss: 1.4437158858776094\n",
      "Epoch: 1, Batch: 400, Loss: 1.3536200833320617\n",
      "Epoch: 1, Batch: 500, Loss: 1.2792512392997741\n",
      "Epoch: 2, Batch: 100, Loss: 1.2004874736070632\n",
      "Epoch: 2, Batch: 200, Loss: 1.162323551774025\n",
      "Epoch: 2, Batch: 300, Loss: 1.1214256006479264\n",
      "Epoch: 2, Batch: 400, Loss: 1.090838366150856\n",
      "Epoch: 2, Batch: 500, Loss: 1.0704428434371949\n",
      "Epoch: 3, Batch: 100, Loss: 0.990564689040184\n",
      "Epoch: 3, Batch: 200, Loss: 0.9863637989759445\n",
      "Epoch: 3, Batch: 300, Loss: 0.9489084368944168\n",
      "Epoch: 3, Batch: 400, Loss: 0.9432619279623031\n",
      "Epoch: 3, Batch: 500, Loss: 0.9493747860193252\n",
      "Epoch: 4, Batch: 100, Loss: 0.8571495884656906\n",
      "Epoch: 4, Batch: 200, Loss: 0.8672626495361329\n",
      "Epoch: 4, Batch: 300, Loss: 0.8416435903310776\n",
      "Epoch: 4, Batch: 400, Loss: 0.8461024391651154\n",
      "Epoch: 4, Batch: 500, Loss: 0.8499041819572448\n",
      "Epoch: 5, Batch: 100, Loss: 0.7442867940664292\n",
      "Epoch: 5, Batch: 200, Loss: 0.7612364107370376\n",
      "Epoch: 5, Batch: 300, Loss: 0.7742611849308014\n",
      "Epoch: 5, Batch: 400, Loss: 0.7753444558382034\n",
      "Epoch: 5, Batch: 500, Loss: 0.7570386415719986\n",
      "Epoch: 6, Batch: 100, Loss: 0.6559150275588036\n",
      "Epoch: 6, Batch: 200, Loss: 0.6933291202783585\n",
      "Epoch: 6, Batch: 300, Loss: 0.7055953133106232\n",
      "Epoch: 6, Batch: 400, Loss: 0.6777889779210091\n",
      "Epoch: 6, Batch: 500, Loss: 0.6695205783843994\n",
      "Epoch: 7, Batch: 100, Loss: 0.5910980385541916\n",
      "Epoch: 7, Batch: 200, Loss: 0.6046317708492279\n",
      "Epoch: 7, Batch: 300, Loss: 0.6173243600130082\n",
      "Epoch: 7, Batch: 400, Loss: 0.610400702059269\n",
      "Epoch: 7, Batch: 500, Loss: 0.6151211354136467\n",
      "Epoch: 8, Batch: 100, Loss: 0.5061125060915947\n",
      "Epoch: 8, Batch: 200, Loss: 0.5357214397192002\n",
      "Epoch: 8, Batch: 300, Loss: 0.5249553829431534\n",
      "Epoch: 8, Batch: 400, Loss: 0.5500462111830712\n",
      "Epoch: 8, Batch: 500, Loss: 0.5572543334960938\n",
      "Epoch: 9, Batch: 100, Loss: 0.43428040385246275\n",
      "Epoch: 9, Batch: 200, Loss: 0.47487182408571244\n",
      "Epoch: 9, Batch: 300, Loss: 0.47249694854021074\n",
      "Epoch: 9, Batch: 400, Loss: 0.4764180690050125\n",
      "Epoch: 9, Batch: 500, Loss: 0.48385439202189445\n",
      "Epoch: 10, Batch: 100, Loss: 0.3746586111187935\n",
      "Epoch: 10, Batch: 200, Loss: 0.38763272657990455\n",
      "Epoch: 10, Batch: 300, Loss: 0.4136834087967873\n",
      "Epoch: 10, Batch: 400, Loss: 0.41059489965438845\n",
      "Epoch: 10, Batch: 500, Loss: 0.42192476451396943\n",
      "Validation Accuracy: 69.8%\n",
      "Fold: 3\n",
      "Epoch: 1, Batch: 100, Loss: 1.9139429306983948\n",
      "Epoch: 1, Batch: 200, Loss: 1.5233371436595917\n",
      "Epoch: 1, Batch: 300, Loss: 1.4220341372489929\n",
      "Epoch: 1, Batch: 400, Loss: 1.3296605694293975\n",
      "Epoch: 1, Batch: 500, Loss: 1.2504008734226226\n",
      "Epoch: 2, Batch: 100, Loss: 1.1575286012887955\n",
      "Epoch: 2, Batch: 200, Loss: 1.096298342347145\n",
      "Epoch: 2, Batch: 300, Loss: 1.0879587239027024\n",
      "Epoch: 2, Batch: 400, Loss: 1.050541375875473\n",
      "Epoch: 2, Batch: 500, Loss: 1.0311047995090485\n",
      "Epoch: 3, Batch: 100, Loss: 0.9478957927227021\n",
      "Epoch: 3, Batch: 200, Loss: 0.9489574593305588\n",
      "Epoch: 3, Batch: 300, Loss: 0.9311308896541596\n",
      "Epoch: 3, Batch: 400, Loss: 0.9225232702493668\n",
      "Epoch: 3, Batch: 500, Loss: 0.9064163655042649\n",
      "Epoch: 4, Batch: 100, Loss: 0.8307331866025924\n",
      "Epoch: 4, Batch: 200, Loss: 0.8505755108594895\n",
      "Epoch: 4, Batch: 300, Loss: 0.8230434060096741\n",
      "Epoch: 4, Batch: 400, Loss: 0.826616644859314\n",
      "Epoch: 4, Batch: 500, Loss: 0.8213823729753494\n",
      "Epoch: 5, Batch: 100, Loss: 0.7277958881855011\n",
      "Epoch: 5, Batch: 200, Loss: 0.7409966826438904\n",
      "Epoch: 5, Batch: 300, Loss: 0.7435527935624122\n",
      "Epoch: 5, Batch: 400, Loss: 0.7598945617675781\n",
      "Epoch: 5, Batch: 500, Loss: 0.7410832184553147\n",
      "Epoch: 6, Batch: 100, Loss: 0.6479118752479553\n",
      "Epoch: 6, Batch: 200, Loss: 0.6513918575644493\n",
      "Epoch: 6, Batch: 300, Loss: 0.6570534247159958\n",
      "Epoch: 6, Batch: 400, Loss: 0.6840652710199356\n",
      "Epoch: 6, Batch: 500, Loss: 0.6793456187844277\n",
      "Epoch: 7, Batch: 100, Loss: 0.5530561354756355\n",
      "Epoch: 7, Batch: 200, Loss: 0.5957435250282288\n",
      "Epoch: 7, Batch: 300, Loss: 0.6001734113693238\n",
      "Epoch: 7, Batch: 400, Loss: 0.6164224827289582\n",
      "Epoch: 7, Batch: 500, Loss: 0.606882081925869\n",
      "Epoch: 8, Batch: 100, Loss: 0.5148715820908546\n",
      "Epoch: 8, Batch: 200, Loss: 0.5145639514923096\n",
      "Epoch: 8, Batch: 300, Loss: 0.5336096891760826\n",
      "Epoch: 8, Batch: 400, Loss: 0.5429402908682823\n",
      "Epoch: 8, Batch: 500, Loss: 0.5319904017448426\n",
      "Epoch: 9, Batch: 100, Loss: 0.4320544795691967\n",
      "Epoch: 9, Batch: 200, Loss: 0.4467471322417259\n",
      "Epoch: 9, Batch: 300, Loss: 0.4746040350198746\n",
      "Epoch: 9, Batch: 400, Loss: 0.4706004065275192\n",
      "Epoch: 9, Batch: 500, Loss: 0.45990306794643404\n",
      "Epoch: 10, Batch: 100, Loss: 0.3676219579577446\n",
      "Epoch: 10, Batch: 200, Loss: 0.38852440372109415\n",
      "Epoch: 10, Batch: 300, Loss: 0.3987247625738382\n",
      "Epoch: 10, Batch: 400, Loss: 0.42328723445534705\n",
      "Epoch: 10, Batch: 500, Loss: 0.41707486361265184\n",
      "Validation Accuracy: 68.77%\n",
      "Fold: 4\n",
      "Epoch: 1, Batch: 100, Loss: 2.0582348775863646\n",
      "Epoch: 1, Batch: 200, Loss: 1.565155222415924\n",
      "Epoch: 1, Batch: 300, Loss: 1.4780801737308502\n",
      "Epoch: 1, Batch: 400, Loss: 1.3906654620170593\n",
      "Epoch: 1, Batch: 500, Loss: 1.3327271926403046\n",
      "Epoch: 2, Batch: 100, Loss: 1.2460598450899125\n",
      "Epoch: 2, Batch: 200, Loss: 1.2244946789741515\n",
      "Epoch: 2, Batch: 300, Loss: 1.1871845346689225\n",
      "Epoch: 2, Batch: 400, Loss: 1.128675108551979\n",
      "Epoch: 2, Batch: 500, Loss: 1.1290214192867278\n",
      "Epoch: 3, Batch: 100, Loss: 1.0669589799642563\n",
      "Epoch: 3, Batch: 200, Loss: 1.0270041000843049\n",
      "Epoch: 3, Batch: 300, Loss: 1.0182808339595795\n",
      "Epoch: 3, Batch: 400, Loss: 0.9911028409004211\n",
      "Epoch: 3, Batch: 500, Loss: 0.9854011648893356\n",
      "Epoch: 4, Batch: 100, Loss: 0.9131947326660156\n",
      "Epoch: 4, Batch: 200, Loss: 0.9173480582237243\n",
      "Epoch: 4, Batch: 300, Loss: 0.9002969914674759\n",
      "Epoch: 4, Batch: 400, Loss: 0.8891365283727646\n",
      "Epoch: 4, Batch: 500, Loss: 0.8557043701410294\n",
      "Epoch: 5, Batch: 100, Loss: 0.7931829261779785\n",
      "Epoch: 5, Batch: 200, Loss: 0.8084667718410492\n",
      "Epoch: 5, Batch: 300, Loss: 0.8124752533435822\n",
      "Epoch: 5, Batch: 400, Loss: 0.7946894246339798\n",
      "Epoch: 5, Batch: 500, Loss: 0.7705044966936111\n",
      "Epoch: 6, Batch: 100, Loss: 0.7223219522833824\n",
      "Epoch: 6, Batch: 200, Loss: 0.6995338752865792\n",
      "Epoch: 6, Batch: 300, Loss: 0.7020595380663872\n",
      "Epoch: 6, Batch: 400, Loss: 0.7183348220586777\n",
      "Epoch: 6, Batch: 500, Loss: 0.6956290465593338\n",
      "Epoch: 7, Batch: 100, Loss: 0.6124208396673203\n",
      "Epoch: 7, Batch: 200, Loss: 0.6382253637909889\n",
      "Epoch: 7, Batch: 300, Loss: 0.6183115464448928\n",
      "Epoch: 7, Batch: 400, Loss: 0.6287682837247849\n",
      "Epoch: 7, Batch: 500, Loss: 0.6496047866344452\n",
      "Epoch: 8, Batch: 100, Loss: 0.516564159989357\n",
      "Epoch: 8, Batch: 200, Loss: 0.553064611852169\n",
      "Epoch: 8, Batch: 300, Loss: 0.5559177094697952\n",
      "Epoch: 8, Batch: 400, Loss: 0.581530442237854\n",
      "Epoch: 8, Batch: 500, Loss: 0.5663790884613991\n",
      "Epoch: 9, Batch: 100, Loss: 0.455523898601532\n",
      "Epoch: 9, Batch: 200, Loss: 0.4866232305765152\n",
      "Epoch: 9, Batch: 300, Loss: 0.48334134116768834\n",
      "Epoch: 9, Batch: 400, Loss: 0.4926941579580307\n",
      "Epoch: 9, Batch: 500, Loss: 0.5036930304765701\n",
      "Epoch: 10, Batch: 100, Loss: 0.3746917378902435\n",
      "Epoch: 10, Batch: 200, Loss: 0.40903743356466293\n",
      "Epoch: 10, Batch: 300, Loss: 0.42309378400444986\n",
      "Epoch: 10, Batch: 400, Loss: 0.4252022838592529\n",
      "Epoch: 10, Batch: 500, Loss: 0.4434062045812607\n",
      "Validation Accuracy: 69.82%\n",
      "Fold: 5\n",
      "Epoch: 1, Batch: 100, Loss: 1.8771827793121338\n",
      "Epoch: 1, Batch: 200, Loss: 1.5114916896820068\n",
      "Epoch: 1, Batch: 300, Loss: 1.3566905176639557\n",
      "Epoch: 1, Batch: 400, Loss: 1.2847958087921143\n",
      "Epoch: 1, Batch: 500, Loss: 1.2191651129722596\n",
      "Epoch: 2, Batch: 100, Loss: 1.136735296845436\n",
      "Epoch: 2, Batch: 200, Loss: 1.1110558861494064\n",
      "Epoch: 2, Batch: 300, Loss: 1.0708941143751145\n",
      "Epoch: 2, Batch: 400, Loss: 1.0625618183612824\n",
      "Epoch: 2, Batch: 500, Loss: 0.9973955726623536\n",
      "Epoch: 3, Batch: 100, Loss: 0.9346392279863358\n",
      "Epoch: 3, Batch: 200, Loss: 0.9392353177070618\n",
      "Epoch: 3, Batch: 300, Loss: 0.8988771837949753\n",
      "Epoch: 3, Batch: 400, Loss: 0.9105584931373596\n",
      "Epoch: 3, Batch: 500, Loss: 0.9156631851196289\n",
      "Epoch: 4, Batch: 100, Loss: 0.827520389854908\n",
      "Epoch: 4, Batch: 200, Loss: 0.8166512036323548\n",
      "Epoch: 4, Batch: 300, Loss: 0.8159460473060608\n",
      "Epoch: 4, Batch: 400, Loss: 0.810635141134262\n",
      "Epoch: 4, Batch: 500, Loss: 0.8038605719804763\n",
      "Epoch: 5, Batch: 100, Loss: 0.7248961585760116\n",
      "Epoch: 5, Batch: 200, Loss: 0.7380472299456596\n",
      "Epoch: 5, Batch: 300, Loss: 0.728611951470375\n",
      "Epoch: 5, Batch: 400, Loss: 0.7345060938596726\n",
      "Epoch: 5, Batch: 500, Loss: 0.7197598946094513\n",
      "Epoch: 6, Batch: 100, Loss: 0.6490630710124969\n",
      "Epoch: 6, Batch: 200, Loss: 0.6509958904981613\n",
      "Epoch: 6, Batch: 300, Loss: 0.6447780087590218\n",
      "Epoch: 6, Batch: 400, Loss: 0.6589729979634285\n",
      "Epoch: 6, Batch: 500, Loss: 0.6569528484344482\n",
      "Epoch: 7, Batch: 100, Loss: 0.5568410593271256\n",
      "Epoch: 7, Batch: 200, Loss: 0.578093236386776\n",
      "Epoch: 7, Batch: 300, Loss: 0.5922977373003959\n",
      "Epoch: 7, Batch: 400, Loss: 0.588009096980095\n",
      "Epoch: 7, Batch: 500, Loss: 0.5858732998371124\n",
      "Epoch: 8, Batch: 100, Loss: 0.4755699184536934\n",
      "Epoch: 8, Batch: 200, Loss: 0.5144700047373771\n",
      "Epoch: 8, Batch: 300, Loss: 0.5192525517940522\n",
      "Epoch: 8, Batch: 400, Loss: 0.5052341210842133\n",
      "Epoch: 8, Batch: 500, Loss: 0.532907841205597\n",
      "Epoch: 9, Batch: 100, Loss: 0.40614490702748296\n",
      "Epoch: 9, Batch: 200, Loss: 0.4341237984597683\n",
      "Epoch: 9, Batch: 300, Loss: 0.4580855971574783\n",
      "Epoch: 9, Batch: 400, Loss: 0.44965936362743375\n",
      "Epoch: 9, Batch: 500, Loss: 0.4644847059249878\n",
      "Epoch: 10, Batch: 100, Loss: 0.34344740882515906\n",
      "Epoch: 10, Batch: 200, Loss: 0.3746747364103794\n",
      "Epoch: 10, Batch: 300, Loss: 0.38820752039551737\n",
      "Epoch: 10, Batch: 400, Loss: 0.3894914619624615\n",
      "Epoch: 10, Batch: 500, Loss: 0.38242304652929304\n",
      "Validation Accuracy: 70.22%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 设置随机种子以确保实验的可重复性\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 网络模型的建立\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 神经网络的输入为 三个通道\n",
    "        # Conv2d 参数：\n",
    "        # （1）in_channels(int)输入特征矩阵的深度（图片通道数）\n",
    "        # （2）out_channels(int)为卷积核的个数\n",
    "        # （3）kerner_size(int or tuple)为卷积核的尺寸\n",
    "        self.conv1 = nn.Conv2d(3, 28, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(28, 180, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(180, 320, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(320, 640, 3, padding=1)\n",
    "\n",
    "        # 批归一化\n",
    "        self.bn1 = nn.BatchNorm2d(28)\n",
    "        self.bn2 = nn.BatchNorm2d(180)\n",
    "        self.bn3 = nn.BatchNorm2d(320)\n",
    "        self.bn4 = nn.BatchNorm2d(640)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(640 * 2 * 2, 300)\n",
    "        self.fc2 = nn.Linear(300, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out) \n",
    "        out = f.relu(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.pool(f.relu(self.bn2(self.conv2(out))))\n",
    "        # out = self.dropout(out)\n",
    "\n",
    "        out = self.pool(f.relu(self.bn3(self.conv3(out))))\n",
    "        # out = self.dropout(out)\n",
    "\n",
    "        out = self.pool(f.relu(self.bn4(self.conv4(out))))\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = out.view(-1, 640 * 2 * 2)\n",
    "        out = f.relu(self.fc1(out))\n",
    "        # out = self.dropout(out)\n",
    "        out = f.relu(self.fc2(out))\n",
    "        # out = self.dropout(out)\n",
    "        # out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        # 添加L2正则化\n",
    "        l2_reg = None\n",
    "        for param in self.parameters():\n",
    "            if l2_reg is None:\n",
    "                l2_reg = param.norm(2)\n",
    "            else:\n",
    "                l2_reg = l2_reg + param.norm(2)\n",
    "        out = out + 0.001 * l2_reg\n",
    "\n",
    "        return out\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 加载CIFAR数据集\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 定义交叉验证的折数\n",
    "num_folds = 5\n",
    "num_epoch = 10\n",
    "\n",
    "\n",
    "# 进行交叉验证\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "models = []\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(trainset)):\n",
    "    print(f\"Fold: {fold+1}\")\n",
    "\n",
    "    # 创建训练集和验证集的数据加载器\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=80, sampler=train_sampler)\n",
    "    valloader = torch.utils.data.DataLoader(trainset, batch_size=80, sampler=val_sampler)\n",
    "\n",
    "    # 创建CNN模型实例\n",
    "    model = CNN().to(device)\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 训练模型\n",
    "    for epoch in range(num_epoch):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 前向传播、反向传播和优化\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print(f'Epoch: {epoch+1}, Batch: {i+1}, Loss: {running_loss / 100}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    # 在验证集上评估模型\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            images = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {accuracy}%')\n",
    "\n",
    "    models.append((model, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0    # 正确率最高的模型索引\n",
    "acc = 0\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    if model[1] > acc:\n",
    "        best = i\n",
    "        acc = model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    dataset = testset,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[best][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型的准确率:\t70.10%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    for features, labels in testloader:\n",
    "        # 与全连接神经网络要求扁平数据不同，CNN对3个通道的数据进行卷积\n",
    "        # 该步骤省略：  features.cc = features.view(-1, 32 * 32)\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(features)\n",
    "        # 获取最大的角标，表示的就是哪个数字\n",
    "        values, indexes = torch.max(pred, axis=1)\n",
    "        # 统计正确的结果\n",
    "        num_correct += (indexes == labels).sum().item()\n",
    "        num_samples += len(labels)\n",
    "\n",
    "    print(f\"模型的准确率:\\t{(num_correct / num_samples):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 1\t 69.9\n",
      "model: 2\t 69.8\n",
      "model: 3\t 68.77\n",
      "model: 4\t 69.82\n",
      "model: 5\t 70.22\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for model in models:\n",
    "    i += 1\n",
    "    print(f\"model: {i}\\t\", model[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
